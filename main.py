import os
import requests
import zipfile
import json
import glob
import logging
import time
from datetime import datetime, timedelta
from config.settings import SDE_JSONL_URL, DATA_DIR, API_SECRET_KEY
from core.importer import SDEImporter

# ==========================================
# é…ç½®ä¸å¸¸é‡ (å»ºè®®åŒæ­¥æ›´æ–° settings.py)
# ==========================================
# FastAPI ç¼“å­˜åˆ·æ–°æ¥å£åœ°å€ (æ ¹æ®ä½ çš„ Docker ç½‘ç»œæˆ–åŸŸåè°ƒæ•´)
API_REFRESH_URL = os.getenv("API_REFRESH_URL", "http://fastapi-app:8000/internal/refresh-market-cache")

VERSION_FILE = os.path.join(DATA_DIR, "current_version.txt")

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# ==========================================
# å·¥å…·å‡½æ•°
# ==========================================

def get_local_version():
    """è¯»å–æœ¬åœ°å­˜å‚¨çš„ SDE æ„å»ºç‰ˆæœ¬"""
    if os.path.exists(VERSION_FILE):
        with open(VERSION_FILE, 'r') as f:
            return f.read().strip()
    return None

def save_local_version(build_num):
    """ä¿å­˜å½“å‰å·²å®Œæˆå¯¼å…¥çš„ç‰ˆæœ¬"""
    with open(VERSION_FILE, 'w') as f:
        f.write(str(build_num))

def fetch_latest_build():
    """è¿æ¥ EVE æœåŠ¡å™¨æ£€æŸ¥æœ€æ–°çš„ SDE æ„å»ºç‰ˆæœ¬"""
    logging.info("æ­£åœ¨è¿æ¥ EVE æœåŠ¡å™¨æ£€æŸ¥ SDE ç‰ˆæœ¬...")
    try:
        response = requests.get(SDE_JSONL_URL, timeout=15)
        response.raise_for_status()
        for line in response.text.splitlines():
            data = json.loads(line)
            if data.get("_key") == "sde":
                return str(data.get("buildNumber"))
    except Exception as e:
        logging.error(f"ç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {e}")
    return None

def notify_api_service():
    """æ•°æ®æ›´æ–°å®Œæˆåï¼Œé€šçŸ¥ FastAPI æœåŠ¡æ¸…ç†å†…å­˜ç¼“å­˜"""
    logging.info(f"ğŸš€ å‡†å¤‡é€šçŸ¥ API æœåŠ¡åˆ·æ–°ç¼“å­˜: {API_REFRESH_URL}")
    try:
        headers = {"X-Internal-Token": API_SECRET_KEY}
        # å‘é€ POST è¯·æ±‚è§¦å‘ FastAPI çš„ .cache_clear()
        response = requests.post(API_REFRESH_URL, headers=headers, timeout=10)
        if response.status_code == 200:
            logging.info("âœ… API æœåŠ¡å“åº”ï¼šå†…å­˜ç¼“å­˜å·²é‡ç½®ï¼Œæ–°æ•°æ®å·²ç”Ÿæ•ˆã€‚")
        else:
            logging.warning(f"âš ï¸ API æœåŠ¡å“åº”å¼‚å¸¸: {response.status_code} - {response.text}")
    except Exception as e:
        logging.error(f"âŒ æ— æ³•è¿æ¥åˆ° API æœåŠ¡è¿›è¡Œåˆ·æ–°: {e}")

# ==========================================
# æ•°æ®åº“åæœŸå¤„ç†é€»è¾‘
# ==========================================

def run_post_processing(importer):
    """åæœŸåŠ å·¥ï¼šæ‰§è¡Œ ANALYZE ä¼˜åŒ– PostgreSQL æŸ¥è¯¢è®¡åˆ’"""
    logging.info("å¼€å§‹æ•°æ®åº“åæœŸåŠ å·¥ (ANALYZE)...")
    try:
        with importer.conn.cursor() as cursor:
            cursor.execute("SELECT tablename FROM pg_tables WHERE schemaname = 'raw';")
            tables = cursor.fetchall()
            for table in tables:
                cursor.execute(f"ANALYZE raw.{table[0]};")
        importer.conn.commit()
        logging.info(f"âœ… åæœŸåŠ å·¥å®Œæˆï¼šå·²ä¼˜åŒ– {len(tables)} å¼ åŸå§‹æ•°æ®è¡¨ã€‚")
    except Exception as e:
        logging.error(f"âš ï¸ åæœŸåŠ å·¥å¤±è´¥: {e}")
        importer.conn.rollback()

def refresh_business_views(importer):
    """è‡ªåŠ¨æ‰§è¡Œ SQL è„šæœ¬åˆ·æ–°ä¸šåŠ¡è§†å›¾åŠç‰©åŒ–è§†å›¾"""
    script_path = os.path.join(os.path.dirname(__file__), "scripts", "init_views.sql")
    if not os.path.exists(script_path):
        logging.warning(f"è·³è¿‡è§†å›¾åˆ·æ–°ï¼šæ‰¾ä¸åˆ°è„šæœ¬æ–‡ä»¶ {script_path}")
        return
    
    logging.info("æ­£åœ¨æ‰§è¡Œ SQL è„šæœ¬åˆ·æ–°ä¸šåŠ¡è§†å›¾åŠç‰©åŒ–è§†å›¾...")
    try:
        with open(script_path, 'r', encoding='utf-8') as f:
            sql_script = f.read()
        with importer.conn.cursor() as cursor:
            # æ‰§è¡ŒåŒ…å« REFRESH MATERIALIZED VIEW çš„ SQL è„šæœ¬
            cursor.execute(sql_script)
        importer.conn.commit()
        logging.info("âœ… ä¸šåŠ¡è§†å›¾ä¸å¸‚åœºèœå•ç‰©åŒ–è§†å›¾å·²åŒæ­¥åˆ·æ–°ã€‚")
    except Exception as e:
        logging.error(f"âš ï¸ åˆ·æ–°ä¸šåŠ¡è§†å›¾å¤±è´¥: {e}")
        importer.conn.rollback()

# ==========================================
# ä»»åŠ¡è°ƒåº¦æ ¸å¿ƒ
# ==========================================

def perform_update_task():
    """å•æ¬¡å®Œæ•´æ›´æ–°ä»»åŠ¡é€»è¾‘ï¼šæ£€æŸ¥ -> ä¸‹è½½ -> å¯¼å…¥ -> åˆ·æ–° -> é€šçŸ¥"""
    importer = None
    zip_filename = None
    try:
        # 1. ç‰ˆæœ¬æ¯”å¯¹
        latest_build = fetch_latest_build()
        local_build = get_local_version()
        
        if not latest_build:
            logging.warning("æœªèƒ½è·å–åˆ°è¿œç¨‹ç‰ˆæœ¬ï¼Œè·³è¿‡æœ¬æ¬¡æ›´æ–°ã€‚")
            return

        if latest_build == local_build:
            logging.info(f"å½“å‰ç‰ˆæœ¬ {local_build} å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°ã€‚")
            return
        
        logging.info(f"æ£€æµ‹åˆ°æ–°ç‰ˆæœ¬: {local_build if local_build else 'None'} -> {latest_build}")
        
        # 2. åˆå§‹åŒ–å¯¼å…¥å™¨å¹¶å‡†å¤‡ç¯å¢ƒ
        importer = SDEImporter()
        os.makedirs(DATA_DIR, exist_ok=True)
        
        # 3. ä¸‹è½½ SDE å‹ç¼©åŒ…
        zip_filename = f"sde_{latest_build}.zip"
        download_url = f"https://developers.eveonline.com/static-data/tranquility/eve-online-static-data-{latest_build}-jsonl.zip"
        
        logging.info(f"æ­£åœ¨ä¸‹è½½ SDE æ„å»ºç‰ˆæœ¬ {latest_build}...")
        with requests.get(download_url, stream=True) as r:
            r.raise_for_status()
            with open(zip_filename, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
                
        # 4. è§£å‹ JSONL æ–‡ä»¶
        logging.info("æ­£åœ¨è§£å‹æ•°æ®...")
        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
            zip_ref.extractall(DATA_DIR)
        
        # 5. éå†å¹¶å¯¼å…¥æ‰€æœ‰ JSONL æ•°æ®åˆ° raw æ¶æ„
        search_pattern = os.path.join(DATA_DIR, "**", "*.jsonl")
        sde_files = glob.glob(search_pattern, recursive=True)
        logging.info(f"å‘ç° {len(sde_files)} ä¸ªæ•°æ®æ–‡ä»¶ï¼Œå‡†å¤‡å¯¼å…¥...")
        for file_path in sde_files:
            importer.auto_import(os.path.abspath(file_path))
        
        # 6. åæœŸæ•°æ®åº“ä¼˜åŒ–ä¸ä¸šåŠ¡è§†å›¾è½¬æ¢
        run_post_processing(importer)
        refresh_business_views(importer)
        
        # 7. æ›´æ–°æœ¬åœ°ç‰ˆæœ¬æ ‡è¯†
        save_local_version(latest_build)
        
        # 8. ã€æ ¸å¿ƒç¯èŠ‚ã€‘æ•°æ®å·²å‡†å¤‡å°±ç»ªï¼Œé€šçŸ¥ FastAPI åˆ·æ–°å†…å­˜ç¼“å­˜
        notify_api_service()
        
        logging.info(f"--- ğŸš€ SDE æ›´æ–°åœ†æ»¡æˆåŠŸï¼šç‰ˆæœ¬ {latest_build} ---")

    except Exception as e:
        logging.error(f"âŒ æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
    finally:
        # å–„åå·¥ä½œï¼šæ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if zip_filename and os.path.exists(zip_filename):
            os.remove(zip_filename)
        for j_file in glob.glob(os.path.join(DATA_DIR, "**", "*.jsonl"), recursive=True):
            try: os.remove(j_file)
            except: pass
        
        if importer:
            importer.close()

def main():
    logging.info("ğŸš€ EVE SDE è‡ªåŠ¨æ›´æ–°å®ˆæŠ¤è¿›ç¨‹å·²å¯åŠ¨ (æ¯æ—¥ 19:00 è¿è¡Œ)...")
    
    # é¦–æ¬¡éƒ¨ç½²æ£€æŸ¥
    if get_local_version() is None:
        logging.info("é¦–æ¬¡éƒ¨ç½²ï¼Œæ£€æµ‹åˆ°æ— æœ¬åœ°ç‰ˆæœ¬è®°å½•ï¼Œç«‹åˆ»æ‰§è¡Œåˆå§‹æ•°æ®å¯¼å…¥...")
        perform_update_task()

    while True:
        now = datetime.now()
        # è®¾å®šæ¯å¤©æ™šä¸Š 19:00 æ‰§è¡Œ
        target = now.replace(hour=19, minute=0, second=0, microsecond=0)
        
        if now >= target:
            target += timedelta(days=1)
            
        sleep_seconds = (target - now).total_seconds()
        logging.info(f"â˜• ç­‰å¾…ä¸­ã€‚ä¸‹æ¬¡æ£€æŸ¥ï¼š{target.strftime('%Y-%m-%d %H:%M:%S')} (çº¦ {round(sleep_seconds/3600, 2)} å°æ—¶å)")
        
        time.sleep(sleep_seconds)
        
        logging.info("â° åˆ°è¾¾é¢„å®šæ—¶é—´ï¼Œå¼€å§‹æ‰§è¡Œæ›´æ–°æ£€æŸ¥...")
        perform_update_task()

if __name__ == "__main__":
    main()