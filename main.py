import os
import requests
import zipfile
import json
import glob
import logging
import time
from datetime import datetime, timedelta
from config.settings import SDE_JSONL_URL, DATA_DIR
from core.importer import SDEImporter

# ==========================================
# æ—¥å¿—é…ç½®
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

VERSION_FILE = os.path.join(DATA_DIR, "current_version.txt")

def get_local_version():
    if os.path.exists(VERSION_FILE):
        with open(VERSION_FILE, 'r') as f:
            return f.read().strip()
    return None

def save_local_version(build_num):
    with open(VERSION_FILE, 'w') as f:
        f.write(str(build_num))

def fetch_latest_build():
    logging.info("æ­£åœ¨è¿æ¥ EVE æœåŠ¡å™¨æ£€æŸ¥ SDE ç‰ˆæœ¬...")
    try:
        # è¿™é‡Œçš„ SDE_JSONL_URL å·²ç»åœ¨ settings.py ä¸­å®šä¹‰
        response = requests.get(SDE_JSONL_URL, timeout=15)
        response.raise_for_status()
        for line in response.text.splitlines():
            data = json.loads(line)
            if data.get("_key") == "sde":
                return str(data.get("buildNumber"))
    except Exception as e:
        logging.error(f"ç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {e}")
    return None

def run_post_processing(importer):
    """åæœŸåŠ å·¥ï¼šæ‰§è¡Œ ANALYZE ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½"""
    logging.info("å¼€å§‹æ•°æ®åº“åæœŸåŠ å·¥ (ANALYZE)...")
    try:
        with importer.conn.cursor() as cursor:
            # è¿™é‡Œçš„ importer.conn å¯¹åº” SDEImporter é‡Œçš„è¿æ¥
            cursor.execute("SELECT tablename FROM pg_tables WHERE schemaname = 'raw';")
            tables = cursor.fetchall()
            for table in tables:
                cursor.execute(f"ANALYZE raw.{table[0]};")
        importer.conn.commit()
        logging.info(f"âœ… åæœŸåŠ å·¥å®Œæˆï¼šå·²ä¼˜åŒ– {len(tables)} å¼ è¡¨ã€‚")
    except Exception as e:
        logging.error(f"âš ï¸ åæœŸåŠ å·¥å¤±è´¥: {e}")
        importer.conn.rollback()

def refresh_business_views(importer):
    """è‡ªåŠ¨æ‰§è¡Œ SQL è„šæœ¬åˆ·æ–°ä¸šåŠ¡è§†å›¾"""
    # è·¯å¾„å¯¹é½ï¼šç¡®ä¿æŒ‡å‘ Docker å®¹å™¨å†…çš„è„šæœ¬ä½ç½®
    script_path = os.path.join(os.path.dirname(__file__), "scripts", "init_views.sql")
    if not os.path.exists(script_path):
        logging.warning(f"è·³è¿‡è§†å›¾åˆ·æ–°ï¼šæ‰¾ä¸åˆ°è„šæœ¬æ–‡ä»¶ {script_path}")
        return
    
    logging.info("æ­£åœ¨æ‰§è¡Œ SQL è„šæœ¬åˆ·æ–°ä¸šåŠ¡è§†å›¾...")
    try:
        with open(script_path, 'r', encoding='utf-8') as f:
            sql_script = f.read()
        with importer.conn.cursor() as cursor:
            cursor.execute(sql_script)
        importer.conn.commit()
        logging.info("âœ… ä¸šåŠ¡è§†å›¾ (Public Schema) å·²åŒæ­¥åˆ·æ–°ã€‚")
    except Exception as e:
        logging.error(f"âš ï¸ åˆ·æ–°ä¸šåŠ¡è§†å›¾å¤±è´¥: {e}")
        importer.conn.rollback()

def perform_update_task():
    """å•æ¬¡å®Œæ•´æ›´æ–°ä»»åŠ¡é€»è¾‘"""
    importer = None
    zip_filename = None
    try:
        # 1. æ£€æŸ¥ç‰ˆæœ¬
        latest_build = fetch_latest_build()
        local_build = get_local_version()
        
        if not latest_build:
            return

        if latest_build == local_build:
            logging.info(f"å½“å‰ç‰ˆæœ¬ {local_build} å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°ã€‚")
            return
        
        logging.info(f"æ£€æµ‹åˆ°æ–°ç‰ˆæœ¬: {local_build if local_build else 'None'} -> {latest_build}")
        
        # 2. åªæœ‰åœ¨ç¡®å®šè¦æ›´æ–°æ—¶æ‰åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ï¼ŒèŠ‚çœèµ„æº
        importer = SDEImporter()
        os.makedirs(DATA_DIR, exist_ok=True)
        
        # 3. ä¸‹è½½
        zip_filename = f"sde_{latest_build}.zip"
        download_url = f"https://developers.eveonline.com/static-data/tranquility/eve-online-static-data-{latest_build}-jsonl.zip"
        
        logging.info(f"æ­£åœ¨ä¸‹è½½ SDE æ„å»ºç‰ˆæœ¬ {latest_build}...")
        with requests.get(download_url, stream=True) as r:
            r.raise_for_status()
            with open(zip_filename, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
                
        # 4. è§£å‹
        logging.info("æ­£åœ¨è§£å‹æ•°æ®...")
        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
            zip_ref.extractall(DATA_DIR)
        
        # 5. éå†å¯¼å…¥
        search_pattern = os.path.join(DATA_DIR, "**", "*.jsonl")
        sde_files = glob.glob(search_pattern, recursive=True)
        for file_path in sde_files:
            # è°ƒç”¨æ•´åˆåå¸¦æ‰¹é‡å¯¼å…¥åŠŸèƒ½çš„ auto_import
            importer.auto_import(os.path.abspath(file_path))
        
        # 6. åæœŸç»´æŠ¤
        run_post_processing(importer)
        refresh_business_views(importer)
        
        # 7. æ›´æ–°æœ¬åœ°ç‰ˆæœ¬é”
        save_local_version(latest_build)
        logging.info(f"--- ğŸš€ SDE æ›´æ–°åœ†æ»¡æˆåŠŸï¼šç‰ˆæœ¬ {latest_build} ---")

    except Exception as e:
        logging.error(f"âŒ æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
    finally:
        # æ¸…ç†å·¥ä½œ
        if zip_filename and os.path.exists(zip_filename):
            os.remove(zip_filename)
        # æ¸…ç†é—ç•™çš„ jsonl æ–‡ä»¶
        for j_file in glob.glob(os.path.join(DATA_DIR, "**", "*.jsonl"), recursive=True):
            try: os.remove(j_file)
            except: pass
        
        # æ˜¾å¼å…³é—­æ•°æ®åº“è¿æ¥
        if importer:
            importer.close()

def main():
    logging.info("ğŸš€ EVE SDE è‡ªåŠ¨æ›´æ–°å®ˆæŠ¤è¿›ç¨‹å·²å¯åŠ¨ (å®šæ—¶æ¨¡å¼ï¼šæ¯æ—¥ 19:00)...")
    
    # é¦–æ¬¡å¯åŠ¨ï¼šå¦‚æœæ²¡æœ‰ç‰ˆæœ¬è®°å½•ï¼Œç«‹åˆ»æ‰§è¡Œä¸€æ¬¡
    if get_local_version() is None:
        logging.info("é¦–æ¬¡éƒ¨ç½²ï¼Œæ£€æµ‹åˆ°æ— æœ¬åœ°ç‰ˆæœ¬è®°å½•ï¼Œç«‹åˆ»æ‰§è¡Œåˆå§‹æ•°æ®å¯¼å…¥...")
        perform_update_task()

    while True:
        now = datetime.now()
        target = now.replace(hour=19, minute=0, second=0, microsecond=0)
        
        if now >= target:
            target += timedelta(days=1)
            
        sleep_seconds = (target - now).total_seconds()
        logging.info(f"â˜• è¿›å…¥ç­‰å¾…æ¨¡å¼ã€‚ä¸‹æ¬¡æ£€æŸ¥ï¼š{target.strftime('%Y-%m-%d %H:%M:%S')} (çº¦ {round(sleep_seconds/3600, 2)} å°æ—¶å)")
        
        time.sleep(sleep_seconds)
        
        logging.info("â° åˆ°è¾¾é¢„å®šæ—¶é—´ï¼Œå¼€å§‹æ‰§è¡Œæ›´æ–°ä»»åŠ¡...")
        perform_update_task()

if __name__ == "__main__":
    main()