import os
import requests
import zipfile
import json
import glob
import logging  # å¼•å…¥æ—¥å¿—æ¨¡å—
from config.settings import SDE_JSONL_URL, DATA_DIR
from core.importer import SDEImporter

# ==========================================
# æ—¥å¿—é…ç½®ï¼š[æ—¶é—´] [çº§åˆ«] æ¶ˆæ¯
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

VERSION_FILE = "current_version.txt"

def get_local_version():
    if os.path.exists(VERSION_FILE):
        with open(VERSION_FILE, 'r') as f:
            return f.read().strip()
    return None

def save_local_version(build_num):
    with open(VERSION_FILE, 'w') as f:
        f.write(str(build_num))

def fetch_latest_build():
    logging.info("æ­£åœ¨è¿æ¥ EVE æœåŠ¡å™¨æ£€æŸ¥ SDE ç‰ˆæœ¬...")
    try:
        response = requests.get(SDE_JSONL_URL, timeout=15)
        response.raise_for_status()
        for line in response.text.splitlines():
            data = json.loads(line)
            if data.get("_key") == "sde":
                return str(data.get("buildNumber"))
    except Exception as e:
        logging.error(f"ç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {e}")
    return None

def run_post_processing(importer):
    logging.info("å¼€å§‹æ•°æ®åº“åæœŸåŠ å·¥ (ANALYZE)...")
    try:
        with importer.conn.cursor() as cursor:
            cursor.execute("SELECT tablename FROM pg_tables WHERE schemaname = 'raw';")
            tables = cursor.fetchall()
            for table in tables:
                cursor.execute(f"ANALYZE raw.{table[0]};")
        importer.conn.commit()
        logging.info(f"âœ… åæœŸåŠ å·¥å®Œæˆï¼šå·²ä¼˜åŒ– {len(tables)} å¼ è¡¨ã€‚")
    except Exception as e:
        logging.error(f"âš ï¸ åæœŸåŠ å·¥å¤±è´¥: {e}")
        importer.conn.rollback()

def main():
    # 1. åˆå§‹åŒ–
    importer = SDEImporter()
    os.makedirs(DATA_DIR, exist_ok=True)
    
    # 2. ç‰ˆæœ¬æ£€æŸ¥
    latest_build = fetch_latest_build()
    local_build = get_local_version()
    
    if not latest_build:
        logging.warning("æœªèƒ½è·å–åˆ°è¿œç¨‹ç‰ˆæœ¬å·ï¼Œè·³è¿‡æ›´æ–°ã€‚")
        return

    if latest_build == local_build:
        logging.info(f"å½“å‰ç‰ˆæœ¬ {local_build} å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°ã€‚")
        return
    
    logging.info(f"æ£€æµ‹åˆ°æ–°ç‰ˆæœ¬: {local_build if local_build else 'None'} -> {latest_build}")
    
    # 3. ä¸‹è½½ä¸å¯¼å…¥
    zip_filename = f"sde_{latest_build}.zip"
    download_url = f"https://developers.eveonline.com/static-data/tranquility/eve-online-static-data-{latest_build}-jsonl.zip"
    
    try:
        logging.info(f"æ­£åœ¨ä¸‹è½½ SDE æ„å»ºç‰ˆæœ¬ {latest_build}...")
        r = requests.get(download_url, stream=True)
        with open(zip_filename, 'wb') as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
                
        logging.info("æ­£åœ¨è§£å‹æ•°æ®åˆ° /data ç›®å½•...")
        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
            zip_ref.extractall(DATA_DIR)
        
        # C. ã€å…³é”®ä¿®æ”¹ã€‘é€’å½’æŸ¥æ‰¾æ‰€æœ‰å­ç›®å½•ä¸‹çš„ jsonl æ–‡ä»¶
        # ä½¿ç”¨ **/*.jsonl å¹¶è®¾ç½® recursive=True
        search_pattern = os.path.join(DATA_DIR, "**", "*.jsonl")
        sde_files = glob.glob(search_pattern, recursive=True)
        
        logging.info(f"æ‰¾åˆ° {len(sde_files)} ä¸ªæ–‡ä»¶ã€‚å¼€å§‹å¯¼å…¥...")
        
        for file_path in sde_files:
            try:
                # ã€å…³é”®ä¿®æ”¹ã€‘ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œé˜²æ­¢ open() æ‰¾ä¸åˆ°æ–‡ä»¶
                abs_path = os.path.abspath(file_path)
                importer.auto_import(abs_path)
            except Exception as e:
                logging.error(f"å¯¼å…¥ {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        # 4. æ‰§è¡ŒåŠ å·¥é€»è¾‘
        run_post_processing(importer)
        
        save_local_version(latest_build)
        logging.info(f"--- ğŸš€ SDE æ›´æ–°åœ†æ»¡æˆåŠŸï¼šç‰ˆæœ¬ {latest_build} ---")

    except Exception as e:
        logging.error(f"âŒ æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        
    finally:
        # 5. æ¸…ç†ç£ç›˜
        logging.info("æ­£åœ¨æ‰§è¡Œç£ç›˜æ¸…ç†...")
        if os.path.exists(zip_filename):
            os.remove(zip_filename)
        for j_file in glob.glob(os.path.join(DATA_DIR, "*.jsonl")):
            os.remove(j_file)
        logging.info("æ¸…ç†å®Œæˆã€‚")

if __name__ == "__main__":
    main()